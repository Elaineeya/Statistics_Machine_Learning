{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "english-screw",
   "metadata": {},
   "source": [
    "# Lab4 Additonal Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-leone",
   "metadata": {},
   "source": [
    "__Student:__ xuawa284\n",
    "\n",
    "__Student:__ lepzh903"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-garbage",
   "metadata": {},
   "source": [
    "####  In what way did you \"clean up\" or divide up the text into words (in the program; the text files should be left unaffected)? This does not have to be perfect in any sense, but it should at least avoid counting \"lord\", \"Lord\" and \"lord.\" as different words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-ground",
   "metadata": {},
   "source": [
    "The text is first converted to lowercase using the lower() function. This ensures that words are not treated as different due to case differences (for example, “lord” and “Lord” are treated as the same word). \n",
    "\n",
    "Then, the get_words function uses the re.findall(r'\\b\\w+\\b', text) regular expression to divide the text into words. The \\b\\w+\\b pattern matches any word boundary followed by one or more word characters (letters, numbers, or underscores), followed by another word boundary. This effectively splits the text into words and ignores punctuation. So, “lord,” “Lord”, and “lord.” would all be treated as “lord”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-divide",
   "metadata": {},
   "source": [
    "####  Which data structures have you used (such as lists, tuples, dictionaries, sets, ...)? Why does that choice make sense? You do not have to do any extensive research on the topics, or try to find exotic modern data structures, but you should reflect on which of the standard data types (or variants thereof) make sense. If you have tried some other solution and updated your code later on, feel free to discuss the effects!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-celebrity",
   "metadata": {},
   "source": [
    "Data Structures Used: \n",
    "\n",
    "Lists: Lists are used to store the words and letters extracted from the text. Lists are a good choice here because they are ordered, allowing us to maintain the order of words and letters as they appear in the text.\n",
    "\n",
    "Sets: A set is used to find the number of unique words. Sets are an appropriate choice for this task because they automatically remove duplicates and have a fast membership test, which is useful for counting unique items.\n",
    "\n",
    "Dictionaries (via collections.Counter): Dictionaries are used to create frequency tables for the words and letters, and to store the successors of the most common words. The collections.Counter class is a subclass of dict that makes it easy to count the frequency of elements in a list. Dictionaries are a good choice for frequency tables because they provide fast lookup times, which is important when counting the frequency of elements.\n",
    "\n",
    "These data structures are part of Python’s standard library and are well-suited to the tasks at hand. They provide efficient operations for the tasks we need to perform, such as counting frequencies and finding unique words. They also have clear and concise syntax, which makes the code easier to read and understand. The choice of these data structures is based on their properties and the requirements of the tasks, rather than on any specific research or exotic data structures. The code could be updated to use different data structures if the requirements changed. For example, if we needed to maintain the original order of unique words, we could use a collections.OrderedDict instead of a set. If we needed to count the frequency of pairs of words, we could use a collections.defaultdict of collections.Counter objects. However, for the tasks as they are currently defined, the chosen data structures are appropriate and effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "physical-heading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "x = \"WELCOME\"\n",
    "\n",
    "print(random.choice(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-concord",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
